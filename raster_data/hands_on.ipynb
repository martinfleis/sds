{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Population as a raster grid\n",
        "\n",
        "Until now, all the data you were working with were tables. However, not\n",
        "everything is a table. Raster data are not that common in social\n",
        "geography, but spatial data science is full of it, from satellite\n",
        "imagery to population grids. In this session, you will learn how to work\n",
        "with spatial raster data in Python and how to link raster to vector\n",
        "using the ecosystem around the `xarray` package.\n",
        "\n",
        "## Arrays and their many dimensions\n",
        "\n",
        "Raster data are represented as arrays. Those can take many forms and\n",
        "shapes. You already know `pandas` data structures, so let’s start with\n",
        "those.\n",
        "\n",
        "A `pandas.Series` is a 1-dimensional array with an index. A typical\n",
        "array contains values of the same data type (e.g. `float` numbers), as\n",
        "does a typical `Series`.\n",
        "\n",
        "When it comes to geospatial raster data, one dimension is not enough.\n",
        "Even the most basic raster, something like a [digital terrain\n",
        "model](https://en.wikipedia.org/wiki/Digital_elevation_model) (DTM),\n",
        "requires two dimensions. One represents longitude (or x when projected),\n",
        "while the other latitude (or y), resulting in a 2-dimensional array.\n",
        "\n",
        "But you don’t have to stop there. Take a typical satellite image. The\n",
        "longitude and latitude dimensions are still present, but you have\n",
        "different bands representing blue, green, red and often near-infra-red\n",
        "frequencies, resulting in a 3-dimensional array (`lon`, `lat`, `band`).\n",
        "Throw in time, and you’re now dealing with a 4-dimensional array (`lon`,\n",
        "`lat`, `band`, `time`).\n",
        "\n",
        "All these use cases fall under the umbrella of N-dimensional array\n",
        "handling covered by the `xarray` package. Whereas a `pandas.Series` is a\n",
        "1-dimensional array with an index, `xarray.DataArray` is an\n",
        "N-dimensional array with N indexes. Combining multiple `Series` gives\n",
        "you a `pandas.DataFrame`, where each column can have a different data\n",
        "type (e.g. one numbers, other names). Combining multiple\n",
        "`xarray.DataArray`s gives you a `xarray.Dataset`, where each array can\n",
        "have a different data type. There’s a lot of similarity between `pandas`\n",
        "and `xarray`, but also some differences.\n",
        "\n",
        "Let’s read some raster and explore `xarray` objects in practice.\n",
        "\n",
        "``` py\n",
        "import datashader as ds\n",
        "import geopandas as gpd\n",
        "import rioxarray\n",
        "import xarray as xr\n",
        "import osmnx as ox\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xvec\n",
        "\n",
        "from geocube.api.core import make_geocube\n",
        "```\n",
        "\n",
        "## Population grids\n",
        "\n",
        "Today, you will be working with the data from the [Global Human\n",
        "Settlement Layer](https://ghsl.jrc.ec.europa.eu/datasets.php) (GHSL)\n",
        "developed by the Joint Research Centre of the European Commission.\n",
        "Unlike in all previous hands-on sessions, the data is not pre-processed\n",
        "and you could read it directly from the open data repository. However,\n",
        "since that seems to be a bit unstable lately, use the copy stored as\n",
        "part of this course.\n",
        "\n",
        "The first layer you will open is a population grid. GHSL covers the\n",
        "whole world divided into a set of tiles, each covering an area of 1,000\n",
        "by 1,000 km at a resolution of 100m per pixel. The link below points to\n",
        "a single tile[1] covering most of Eastern Europe.\n",
        "\n",
        "``` py\n",
        "pop_url = (\n",
        "    \"https://martinfleischmann.net/sds/raster_data/data/\"\n",
        "    \"GHS_POP_E2030_GLOBE_R2023A_54009_100_V1_0_R4_C20.zip\"\n",
        "      )\n",
        "pop_url\n",
        "```\n",
        "\n",
        "Line 1  \n",
        "The URL is long. It may be better to write it as a multi-line string to\n",
        "avoid a long line.\n",
        "\n",
        "> **Original data**\n",
        ">\n",
        "> You can, alternatively, try reading the original data directly using\n",
        "> this URL:\n",
        ">\n",
        "> ``` py\n",
        "> pop_url = (\n",
        ">     \"https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/\"\n",
        ">     \"GHS_POP_GLOBE_R2023A/GHS_POP_E2030_GLOBE_R2023A_54009_100/\"\n",
        ">     \"V1-0/tiles/GHS_POP_E2030_GLOBE_R2023A_54009_100_V1_0_R4_C20.zip\"\n",
        ">       )\n",
        "> ```\n",
        "\n",
        "The `pop_url` points to a ZIP file. Within that ZIP file is a\n",
        "[GeoTIFF](https://en.wikipedia.org/wiki/GeoTIFF) containing the actual\n",
        "raster. There is often no need to download and unzip the file as there’s\n",
        "a good chance you can read it directly.\n",
        "\n",
        "### Reading rasters with `rioxarray`\n",
        "\n",
        "`xarray`, like `pandas` is an agnostic library. It is designed for\n",
        "N-dimensional arrays but not necessarily geospatial arrays (although\n",
        "that is often the case…). It means that by default, it is not able to\n",
        "read geospatial file formats like GeoTIFF. That is where `rioxarray`\n",
        "comes in. It comes with the support of the usual geo-specific things\n",
        "like specific file formats or CRS.\n",
        "\n",
        "``` py\n",
        "p = f\"zip+{pop_url}!GHS_POP_E2030_GLOBE_R2023A_54009_100_V1_0_R4_C20.tif\"\n",
        "population = rioxarray.open_rasterio(p, masked=True)\n",
        "population\n",
        "```\n",
        "\n",
        "Line 1  \n",
        "Create a path to the file inside the ZIP. Add the `\"zip+\"` prefix and\n",
        "then the path to the actual file inside the archive, starting with\n",
        "`\"!\"`.\n",
        "\n",
        "Line 2  \n",
        "Use `rioxarray` to open the file using the lower-level `rasterio`\n",
        "package. With `masked=True` ensure, that the missing values are properly\n",
        "masked out.\n",
        "\n",
        "Above, you can see the representation of the population grid as a\n",
        "`DataArray`. It has three dimensions (`\"band\"`, `\"x\"`, `\"y\"`) with a\n",
        "resolution 1x10,000x10,000 and values as `float`.\n",
        "\n",
        "`rioxarray` gives you a handy `.rio` accessor on `xarray` objects,\n",
        "allowing you to access geospatial-specific tools. Like retrieval of CRS.\n",
        "\n",
        "``` py\n",
        "population.rio.crs\n",
        "```\n",
        "\n",
        "Or the extent of the raster (in the CRS shown above).\n",
        "\n",
        "``` py\n",
        "population.rio.bounds()\n",
        "```\n",
        "\n",
        "The missing, masked data can be represented as as specific value,\n",
        "especially when dealing with integer arrays. You can check which one:\n",
        "\n",
        "``` py\n",
        "population.rio.nodata\n",
        "```\n",
        "\n",
        "### Plotting with `datashader`\n",
        "\n",
        "Plotting a raster with a resolution of 10,000x10,000 pixels can be\n",
        "tricky. Often, the resolution is even larger than that. The best way to\n",
        "plot is to resample the data to a smaller resolution that better fits\n",
        "the screen. A handy tool that can do that quickly is\n",
        "[`datashader`](https://datashader.org). Let’s use it to plot the array\n",
        "as 600x600 pixels.\n",
        "\n",
        "``` py\n",
        "canvas = ds.Canvas(plot_width=600, plot_height=600)\n",
        "agg = canvas.raster(population.where(population>0).sel(band=1))\n",
        "agg\n",
        "```\n",
        "\n",
        "Line 1  \n",
        "Create a canvas with a specific resolution.\n",
        "\n",
        "Line 2  \n",
        "Select pixels with a population more than 0\n",
        "(`population.where(population>0)`), select a single band to get\n",
        "2-dimensional array (`.sel(band=1)`) and pass the result to the canvas.\n",
        "\n",
        "You can see that the result is a new `xarray.DataArray` with a\n",
        "resolution 600x600. The built-in matplotlib-based plotting can easily\n",
        "handle that.\n",
        "\n",
        "``` py\n",
        "# | fig-cap: Population grid resampled to 600x600 pixels\n",
        "_ = agg.plot()\n",
        "```\n",
        "\n",
        "## Clipping based on geometry\n",
        "\n",
        "Daling with large rasters is often impractical if you are interested in\n",
        "a small subset, for example, representing a single city.\n",
        "\n",
        "### Functional Urban Areas\n",
        "\n",
        "In this case, you may want to work only with the data covering Budapest,\n",
        "Hungary, defined by its [functional urban\n",
        "area](https://ghsl.jrc.ec.europa.eu/ghs_fua.php) (FUA), available as\n",
        "another data product on GHSL. FUAs are available as a single GeoPackage\n",
        "with vector geometries.\n",
        "\n",
        "``` py\n",
        "#| classes: explore\n",
        "fua_url = (\n",
        "    \"https://martinfleischmann.net/sds/raster_data/data/\"\n",
        "    \"GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.zip\"\n",
        ")\n",
        "p = f\"zip+{fua_url}!GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.gpkg\"\n",
        "fuas = gpd.read_file(p)\n",
        "budapest = fuas.query(\"eFUA_name == 'Budapest'\")\n",
        "budapest.explore()\n",
        "```\n",
        "\n",
        "Lines 2-5  \n",
        "Get the URL.\n",
        "\n",
        "Line 6  \n",
        "Specify the path to read the file from the ZIP.\n",
        "\n",
        "Line 7  \n",
        "Read the table with `geopandas`.\n",
        "\n",
        "Line 8  \n",
        "Filter only Budapest.\n",
        "\n",
        "> **Original data**\n",
        ">\n",
        "> You can, alternatively, try reading the original data directly using\n",
        "> this URL:\n",
        ">\n",
        "> ``` py\n",
        "> fua_url = (\n",
        ">     \"https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/\"\n",
        ">     \"GHS_FUA_UCDB2015_GLOBE_R2019A/V1-0/\"\n",
        ">     \"GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.zip\"\n",
        "> )\n",
        "> ```\n",
        "\n",
        "If you want to clip the `population` raster to the extent of Budapest\n",
        "FUA, you can use the `clip` method from the `rioxarray` extension of\n",
        "`xarray`.\n",
        "\n",
        "``` py\n",
        "population_bud = population.rio.clip(\n",
        "    budapest.to_crs(population.rio.crs).geometry\n",
        ")\n",
        "population_bud\n",
        "```\n",
        "\n",
        "Line 1  \n",
        "Use `.rio.clip` to clip the geospatial raster to the extent of a\n",
        "geometry.\n",
        "\n",
        "Line 2  \n",
        "Ensure the `budapest` is in the same CRS as the `population` and pass\n",
        "its geometry.\n",
        "\n",
        "The raster is no longer 10,000x10,000 pixels but only 840x830, covering\n",
        "the extent of Budapest FUA. You can easily check that by plotting the\n",
        "clipped array.\n",
        "\n",
        "``` py\n",
        "# | fig-cap: Population grid clipped to Budapest FUA\n",
        "_ = population_bud.plot()\n",
        "```\n",
        "\n",
        "## Array manipulation\n",
        "\n",
        "While this is technically a 3-dimensional array, the dimension `\"band\"`\n",
        "has only one value. Normally, you would get a 2-dimensional array\n",
        "representing a selected band using the `.sel()` method.\n",
        "\n",
        "``` py\n",
        "population_bud.sel(band=1)\n",
        "```\n",
        "\n",
        "But if you have only one band, you can *squeeze* the array and get rid\n",
        "of that dimension that is not needed.\n",
        "\n",
        "``` py\n",
        "population_bud = population_bud.drop_vars(\"band\").squeeze()\n",
        "population_bud\n",
        "```\n",
        "\n",
        "Now a lot what you know from `pandas` works equally in `xarray`. Getting\n",
        "the minimum:\n",
        "\n",
        "``` py\n",
        "population_bud.min()\n",
        "```\n",
        "\n",
        "As expected, there are some cells with no inhabitants.\n",
        "\n",
        "``` py\n",
        "population_bud.max()\n",
        "```\n",
        "\n",
        "The densest cell, on the other hand, has more than 600 people per\n",
        "hectare.\n",
        "\n",
        "``` py\n",
        "population_bud.mean()\n",
        "```\n",
        "\n",
        "Mean is, however, only below 7.\n",
        "\n",
        "``` py\n",
        "population_bud.median()\n",
        "```\n",
        "\n",
        "While the median is 0, there are a lot of cells with 0.\n",
        "\n",
        "> **DataArray vs scalar**\n",
        ">\n",
        "> Notice that `xarray` always returns another `DataArray` even with a\n",
        "> single value. If you want to get that scalar value, you can use\n",
        "> `.item()`.\n",
        ">\n",
        "> ``` py\n",
        "> population_bud.mean().item()\n",
        "> ```\n",
        "\n",
        "You can plot the distribution of values across the array.\n",
        "\n",
        "``` py\n",
        "# | fig-cap: Histogram of population counts\n",
        "_ = population_bud.plot.hist(bins=100)\n",
        "```\n",
        "\n",
        "Indeed, there are a lot of zeros. Let’s filter them out and check the\n",
        "distribution again.\n",
        "\n",
        "``` py\n",
        "# | fig-cap: Histogram of population counts excluding 0\n",
        "_ = population_bud.where(population_bud>0).plot.hist(bins=100)\n",
        "```\n",
        "\n",
        "As with many observations in urban areas, this follows a power-law-like\n",
        "distribution with a lot of observations with tiny values and only a few\n",
        "with large ones.\n",
        "\n",
        "## Array operations\n",
        "\n",
        "Let’s assume that you want to normalise population counts by the\n",
        "built-up volume, which is available as another GHSL product. This time,\n",
        "on a grid again.\n",
        "\n",
        "``` py\n",
        "volume_url = (\n",
        "    \"https://martinfleischmann.net/sds/raster_data/data/\"\n",
        "    \"GHS_BUILT_V_E2030_GLOBE_R2023A_54009_100_V1_0_R4_C20.zip\"\n",
        ")\n",
        "volume_url\n",
        "```\n",
        "\n",
        "> **Backup data**\n",
        ">\n",
        "> You can, alternatively, try reading the original data directly using\n",
        "> this URL:\n",
        ">\n",
        "> ``` py\n",
        "> volume_url = (\n",
        ">     \"https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/\"\n",
        ">     \"GHS_BUILT_V_GLOBE_R2023A/GHS_BUILT_V_E2030_GLOBE_R2023A_54009_100/V1-0/tiles/\"\n",
        ">     \"GHS_BUILT_V_E2030_GLOBE_R2023A_54009_100_V1_0_R4_C20.zip\"\n",
        "> )\n",
        "> ```\n",
        "\n",
        "All work the same as before. You read the GeoTIFF as a `DataArray`.\n",
        "\n",
        "``` py\n",
        "p = f\"zip+{volume_url}!GHS_BUILT_V_E2030_GLOBE_R2023A_54009_100_V1_0_R4_C20.tif\"\n",
        "built_up = rioxarray.open_rasterio(p, masked=True).drop_vars(\"band\").squeeze()\n",
        "built_up\n",
        "```\n",
        "\n",
        "And clip it to the same extent.\n",
        "\n",
        "``` py\n",
        "built_up_bud = built_up.rio.clip(budapest.to_crs(built_up.rio.crs).geometry)\n",
        "built_up_bud\n",
        "```\n",
        "\n",
        "You can quickly check what it looks like.\n",
        "\n",
        "``` py\n",
        "# | fig-cap: Built-up volume\n",
        "_ = built_up_bud.plot(cmap=\"magma_r\")\n",
        "```\n",
        "\n",
        "The two grids are aligned, meaning that pixels with the same coordinates\n",
        "represent the same area. This allows us to directly perform array\n",
        "algebra. Again, you know this from `pandas`.\n",
        "\n",
        "``` py\n",
        "pop_density = population_bud /  built_up_bud\n",
        "pop_density\n",
        "```\n",
        "\n",
        "Line 1  \n",
        "Divide the population by built-up volume to get a normalised value.\n",
        "\n",
        "The result is a new array that inherits spatial information\n",
        "(`spatial_ref`) but contains newly computed values.\n",
        "\n",
        "``` py\n",
        "# | fig-cap: Population grid normalised by the built-up volume\n",
        "_ = pop_density.plot(cmap=\"cividis_r\")\n",
        "```\n",
        "\n",
        "The resulting array can then be saved to a GeoTIFF using `rioxarray`.\n",
        "\n",
        "``` py\n",
        "pop_density.rio.to_raster(\"population_density.tif\")\n",
        "```\n",
        "\n",
        "### Extracting values for locations with `xvec`\n",
        "\n",
        "A common need is to extract values from raster data for a specific\n",
        "location of interest. That is a first type of interaction between raster\n",
        "and vector data (points in this case). To illustrate the use case,\n",
        "create a set of random points covering the area of `budapest`.\n",
        "\n",
        "``` py\n",
        "locations = budapest.sample_points(1000).explode(ignore_index=True)\n",
        "locations.head()\n",
        "```\n",
        "\n",
        "Line 1  \n",
        "`sample_points()` method creates a random sample of the selected size\n",
        "within each geometry in a `GeoSeries`. Each sample set is a `MultiPoint`\n",
        "but in this case, you want individual points. That is when `explode()`\n",
        "is useful, since it *explodes* each multi-part geometry into individual\n",
        "points. Because you are not interested in the original index, you can\n",
        "use `ignore_index=True` to get the default `pd.RangeIndex`.\n",
        "\n",
        "Check how the sample looks on a map.\n",
        "\n",
        "``` py\n",
        "locations.explore()\n",
        "```\n",
        "\n",
        "> **Random sampling and reproducibility**\n",
        ">\n",
        "> The points sampled from `budapest` will be different every time you\n",
        "> run the `sample_points()` method. If you want to fix the result, you\n",
        "> can pass a *seed* value to a random number generator as `rng=42`. With\n",
        "> the same seed value, the result will be always the same. This is\n",
        "> useful, especially if you are interested in the reproducibility of\n",
        "> your code.\n",
        "\n",
        "The `xarray` ecosystem offers many ways of extracting point values.\n",
        "Below, you will use the implementation from the `xvec` package. Create a\n",
        "new `xarray.DataArray` with all three arrays you created so far to see\n",
        "the benefits of using `xvec` below.\n",
        "\n",
        "``` py\n",
        "bud_cube = xr.concat(\n",
        "    [pop_density, population_bud, built_up_bud],\n",
        "    dim=pd.Index(\n",
        "        [\"density\", \"population\", \"built-up volume\"],\n",
        "        name=\"measurement\",\n",
        "    )\n",
        ")\n",
        "bud_cube\n",
        "```\n",
        "\n",
        "Line 1  \n",
        "Use `xr.concat` function to *concatenate* all arrays together.\n",
        "\n",
        "Line 2  \n",
        "Specify which arrays shall be concatenated.\n",
        "\n",
        "Line 3  \n",
        "Define a new dimension created along the axis of concatenation. Use the\n",
        "`pd.Index` to create a new index along this dimension.\n",
        "\n",
        "Line 4  \n",
        "Specify coordinates along the new dimension.\n",
        "\n",
        "Line 5  \n",
        "Give the dimension a name.\n",
        "\n",
        "The resulting `DataArray` is 3-dimensional, compared to 2-dimensional\n",
        "arrays used before. Apart from `x` and `y`, you now have `measurement`\n",
        "as well. Using the new index created above, you can use the `sel()`\n",
        "method to get the original arrays.\n",
        "\n",
        "``` py\n",
        "bud_cube.sel(measurement=\"density\")\n",
        "```\n",
        "\n",
        "Now it is time to take this *cube* and create another based on your\n",
        "points. That can be done using the `.xvec` accessor and its\n",
        "`extract_points` method.\n",
        "\n",
        "``` py\n",
        "vector_cube = bud_cube.drop_vars(\"spatial_ref\").xvec.extract_points(\n",
        "    points=locations.geometry,\n",
        "    x_coords=\"x\",\n",
        "    y_coords=\"y\",\n",
        ")\n",
        "vector_cube\n",
        "```\n",
        "\n",
        "Line 1  \n",
        "Drop `spatial_ref` because it is not interesting for point extraction\n",
        "and use `.xvec.extract_points()`\n",
        "\n",
        "Line 2  \n",
        "Specify the points for which you want to extract the values.\n",
        "\n",
        "Lines 3-4  \n",
        "Specify which dimension of the `bud_cube` `DataArray` represents\n",
        "x-coordinate dimension of geometries and which represents the\n",
        "y-coordinate dimension to match points to the array.\n",
        "\n",
        "The resulting object is still a `DataArray` but a bit different. It is\n",
        "no longer 3-dimensional, although all dimensions of interest\n",
        "(`'density', 'population', 'built-up volume'`) are still there, but\n",
        "2-dimensional. One dimension is `measurement`, and the other is\n",
        "`geometry`, containing the points of interest. With `xvec`, the spatial\n",
        "dimension is reduced, but the remaining dimensionality of the original\n",
        "array is preserved.\n",
        "\n",
        "You can then convert the data into a `geopandas.GeoDataFrame` and work\n",
        "with it as usual.\n",
        "\n",
        "``` py\n",
        "location_data = vector_cube.xvec.to_geopandas()\n",
        "location_data.head()\n",
        "```\n",
        "\n",
        "Check the result on a map to verify that all worked as expected.\n",
        "\n",
        "``` py\n",
        "location_data.explore(\"density\", cmap=\"cividis_r\", tiles=\"CartoDB Positron\")\n",
        "```\n",
        "\n",
        "> **Vector data cubes**\n",
        ">\n",
        "> The data structure `vector_cube` represents is called a vector data\n",
        "> cube. It is a special case of an `xarray` N-dimensional object, where\n",
        "> at least one dimension is indexed by geometries. See more in the [Xvec\n",
        "> documentation](https://xvec.readthedocs.io/en/stable/intro.html).\n",
        "\n",
        "## Zonal statistics with `geocube`\n",
        "\n",
        "Another operation when working with rasters is the transfer of values\n",
        "from an array to a set of polygons. This is called *zonal statistics*\n",
        "and can be done in many ways, depending on the use case. When your\n",
        "polygons are large compared to cells of the array, a good option is to\n",
        "use a `geocube` package.\n",
        "\n",
        "### Downloading OpenStreetMap data\n",
        "\n",
        "You may be interested in the average population density in individual\n",
        "districts of Budapest. One option for getting the geometries\n",
        "representing the districts is the\n",
        "[OpenStreetMap](https://www.openstreetmap.org/). Everything you can see\n",
        "on OpenStreetMap is downloadable. In Python, a recommended way (when not\n",
        "doing large downloads) is the `osmnx` package (imported as `ox`). The\n",
        "detailed explanation of `osmnx` is out of scope for this session, but if\n",
        "you are interested in details, check the official [Getting\n",
        "started](https://osmnx.readthedocs.io/en/stable/getting-started.html)\n",
        "guide.\n",
        "\n",
        "``` py\n",
        "admin_level_9 = ox.features_from_place(\"Budapest\", {\"admin_level\": \"9\"})\n",
        "districts = admin_level_9[admin_level_9.geom_type == \"Polygon\"][\n",
        "    [\"name\", \"name:en\", \"geometry\"]\n",
        "]\n",
        "districts[\"key\"] = range(len(districts))\n",
        "```\n",
        "\n",
        "Line 1  \n",
        "Use `features_from_place` to download features from Budapest. But filter\n",
        "only those tagged with the `admin_level` equal to 9.\n",
        "\n",
        "Line 2  \n",
        "Filter only polygons. The `GeoDataFrame` coming from `osmnx` also\n",
        "contains many LineStrings.\n",
        "\n",
        "Line 3  \n",
        "Retain only three columns that may be useful.\n",
        "\n",
        "Line 5  \n",
        "Create a new column with a *key* - an integer value unique to each\n",
        "observation. That will be useful later.\n",
        "\n",
        "### Plotting raster and vector together\n",
        "\n",
        "Both `xarray` and `geopandas` can create `matplotlib` plots that can be\n",
        "combined to see how the two overlap.\n",
        "\n",
        "``` py\n",
        "# | fig-cap: Overlay of district boundaries over population density\n",
        "f, ax = plt.subplots()\n",
        "pop_density.plot(ax=ax, cmap=\"cividis_r\")\n",
        "districts.to_crs(pop_density.rio.crs).plot(\n",
        "    ax=ax, facecolor=\"none\", edgecolor=\"red\", linewidth=1, aspect=None\n",
        ");\n",
        "```\n",
        "\n",
        "Line 2  \n",
        "Create an empty figure and an axis.\n",
        "\n",
        "Line 3  \n",
        "Plot the population density to the axis.\n",
        "\n",
        "Line 4  \n",
        "Plot the `districts` to the same array, ensuring it is in the same\n",
        "projection.\n",
        "\n",
        "Line 5  \n",
        "Specify the plotting style and disable the automatic setting of the\n",
        "aspect to keep the axis as returned by `xarray`.\n",
        "\n",
        "### Zonal statistics\n",
        "\n",
        "Zonal statistics using `geocube` has three conceptual phases.\n",
        "\n",
        "1.  Convert the geometry to an aligned raster, bringing the ID of each\n",
        "    polygon to a raster format.\n",
        "2.  Merge of the two arrays.\n",
        "3.  Groupby operation using the IDs as grouping keys.\n",
        "\n",
        "Let’s start with the first one.\n",
        "\n",
        "``` py\n",
        "districts_grid = make_geocube(\n",
        "    vector_data=districts,\n",
        "    measurements=[\"key\"],\n",
        "    like=pop_density,\n",
        ")\n",
        "districts_grid\n",
        "```\n",
        "\n",
        "Line 1  \n",
        "Use `make_geocube` imported from `geocube`.\n",
        "\n",
        "Line 2  \n",
        "You want to rasterise `districts` `GeoDataFrame`.\n",
        "\n",
        "Line 3  \n",
        "Use the values in the `\"key\"` column as values of the resulting array.\n",
        "\n",
        "Line 4  \n",
        "Make the array look like `pop_density` to ensure the two are exactly\n",
        "aligned.\n",
        "\n",
        "You can visually check the resulting raster by plotting the `\"key\"`\n",
        "variable.\n",
        "\n",
        "``` py\n",
        "# | fig-cap: Rasterised districts\n",
        "_ = districts_grid.key.plot.imshow(cmap=\"tab20\")\n",
        "```\n",
        "\n",
        "Line 2  \n",
        "`\"tab20\"` is a categorical colour map suitable for the categorical\n",
        "variable stored in `\"key\"`.\n",
        "\n",
        "The second and third steps outlined above can be combined into a single\n",
        "one. You can directly group `pop_density` by the array stored in\n",
        "`districts_grid.key`.\n",
        "\n",
        "``` py\n",
        "grouped_density = pop_density.groupby(districts_grid.key)\n",
        "grouped_density\n",
        "```\n",
        "\n",
        "This gives you a similar `GroupBy` object you know from `pandas`. You\n",
        "can get any type of aggregation from the object and assign it directly\n",
        "back to the `GeoDataFrame`.\n",
        "\n",
        "``` py\n",
        "districts[\"mean_density\"] = grouped_density.mean()\n",
        "```\n",
        "\n",
        "Check the result!\n",
        "\n",
        "``` py\n",
        "#| classes: explore\n",
        "districts.explore(\"mean_density\", cmap=\"cividis_r\", tiles=\"CartoDB Positron\")\n",
        "```\n",
        "\n",
        "> **Additional reading**\n",
        ">\n",
        "> Have a look at the chapter [*Local Spatial\n",
        "> Autocorrelation*](https://geographicdata.science/book/notebooks/07_local_autocorrelation.html#bonus-local-statistics-on-surfaces)\n",
        "> from the Geographic Data Science with Python by @rey2023geographic to\n",
        "> learn how to do LISA on rasters.\n",
        ">\n",
        "> The great resource on xarray is their\n",
        "> [tutorial](https://tutorial.xarray.dev/intro.html).\n",
        "\n",
        "[1] See the distribution of tiles in the [data\n",
        "repository](https://ghsl.jrc.ec.europa.eu/download.php?ds=pop)."
      ],
      "id": "f0a33015-bc76-41bb-8b96-1a1e8543fe03"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "sds",
      "display_name": "sds",
      "language": "python",
      "path": "/home/runner/.local/share/jupyter/kernels/sds"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  }
}